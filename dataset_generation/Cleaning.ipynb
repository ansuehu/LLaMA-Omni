{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc232f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.2-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.2-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [pandas]2m3/4\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed numpy-2.3.2 pandas-2.3.2 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd5a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"/home/andoni/Downloads/output/translated_instruction_0.json\")\n",
    "df['text'] = [str(i) for i in df['text'].values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "1f3242fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = iter(df.itertuples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "54362c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pandas(Index=139, conversation_id=72, text='Zer egingo lukete bazkari kit-ek, nola funtzionatuko lukete horiek? ’')"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3115ddb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "ed3c58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "noise_patterns = [\n",
    "    r\"\\bdisplaystyle\\b\",          # remove 'displaystyle'\n",
    "    r\"[?]{2,}\",                   # 3 or more question marks\n",
    "    r\"[-]{2,}\",                   # 3 or more dashes\n",
    "    r\"[.]{3,}\",                   # 3 or more dots\n",
    "    r\"\\s{2,}\",                    # 3 or more spaces\n",
    "    r\"(?:\\bdisplaystyle\\b\\s*)+\"   # repeated 'displaystyle' sequences\n",
    "    r\"{'translation_text: }\"\n",
    "]\n",
    "\n",
    "# Compile regexes\n",
    "noise_regex = re.compile(\"|\".join(noise_patterns), flags=re.IGNORECASE)\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Remove fillers, noise, and normalize whitespace.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    text = text.strip()\n",
    "    if text.startswith(\"{'translation_text':\") or text.startswith(\"{\\\"translation_text\\\":\"):\n",
    "        text = text.split(\":\", 1)[1]   # keep everything after first :\n",
    "        text = text.lstrip(\" '\\\"\")     # strip quotes/spaces\n",
    "        if text.endswith(\"}\"):\n",
    "            text = text[:-1]\n",
    "        text = text.rstrip(\" '\\\"\")     # strip trailing quotes/spaces\n",
    "\n",
    "    # Remove noise patterns\n",
    "    text = noise_regex.sub(\" \", text)\n",
    "    # Normalize spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(r\":+$\", \"\", text).strip()\n",
    "    text = re.sub(r\"\\b(\\w+)(?: \\1){2,}\\b\", \" \", text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "c7581ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    df = pd.read_json(f\"/home/andoni/Downloads/output/translated_answer_{i}.json\")\n",
    "    df['text'] = [str(j) for j in df['text'].values]\n",
    "    df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "    df.to_json(f\"cleaned_answer_{i}.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "765baf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "2a4cda9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"/home/andoni/Downloads/output/cleaned_answer_0.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "1c257e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hona hemen osasuntsu egoteko hiru aholku: diet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hiru kolore nagusiak gorria, urdina eta horia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Atomo batek hiru zati nagusi ditu: nukleoa, nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Airearen kutsadura murrizteko, garraio publiko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Uraren kutsadura murrizteko, hondakinak behar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42215</th>\n",
       "      <td>19998</td>\n",
       "      <td>Funtsezko trebetasun bigunak komunikazio eragi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42216</th>\n",
       "      <td>19998</td>\n",
       "      <td>Ikastetxeek denboraren kudeaketa irakatsi deza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42217</th>\n",
       "      <td>19998</td>\n",
       "      <td>Ikastetxeek ikasleen aurrerapena ebaluatu deza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42218</th>\n",
       "      <td>19998</td>\n",
       "      <td>Ebaluazioei esker, irakasleek denboran zehar i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42219</th>\n",
       "      <td>19999</td>\n",
       "      <td>Itsaspekoak eta aireko globo beroak garraiobid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42220 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       conversation_id                                               text\n",
       "0                    0  Hona hemen osasuntsu egoteko hiru aholku: diet...\n",
       "1                    1  Hiru kolore nagusiak gorria, urdina eta horia ...\n",
       "2                    2  Atomo batek hiru zati nagusi ditu: nukleoa, nu...\n",
       "3                    3  Airearen kutsadura murrizteko, garraio publiko...\n",
       "4                    3  Uraren kutsadura murrizteko, hondakinak behar ...\n",
       "...                ...                                                ...\n",
       "42215            19998  Funtsezko trebetasun bigunak komunikazio eragi...\n",
       "42216            19998  Ikastetxeek denboraren kudeaketa irakatsi deza...\n",
       "42217            19998  Ikastetxeek ikasleen aurrerapena ebaluatu deza...\n",
       "42218            19998  Ebaluazioei esker, irakasleek denboran zehar i...\n",
       "42219            19999  Itsaspekoak eta aireko globo beroak garraiobid...\n",
       "\n",
       "[42220 rows x 2 columns]"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f02bc1df",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File /home/andoni/Downloads/output/cleaned_answer_0.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m answers = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/andoni/Downloads/output/cleaned_answer_0.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m instructions = pd.read_json(\u001b[33m\"\u001b[39m\u001b[33m/home/andoni/Downloads/output/cleaned_instruction_0.json\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/output/.venv/lib/python3.13/site-packages/pandas/io/json/_json.py:791\u001b[39m, in \u001b[36mread_json\u001b[39m\u001b[34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient != \u001b[33m\"\u001b[39m\u001b[33mtable\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    789\u001b[39m     convert_axes = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m791\u001b[39m json_reader = \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    810\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/output/.venv/lib/python3.13/site-packages/pandas/io/json/_json.py:904\u001b[39m, in \u001b[36mJsonReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[39m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = filepath_or_buffer\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mujson\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28mself\u001b[39m._preprocess_data(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/output/.venv/lib/python3.13/site-packages/pandas/io/json/_json.py:960\u001b[39m, in \u001b[36mJsonReader._get_data_from_filepath\u001b[39m\u001b[34m(self, filepath_or_buffer)\u001b[39m\n\u001b[32m    952\u001b[39m     filepath_or_buffer = \u001b[38;5;28mself\u001b[39m.handles.handle\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m    954\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    955\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer.lower().endswith(\n\u001b[32m   (...)\u001b[39m\u001b[32m    958\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[32m    959\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_or_buffer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    962\u001b[39m     warnings.warn(\n\u001b[32m    963\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing literal json to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mread_json\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in a future version. To read from a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    967\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    968\u001b[39m     )\n",
      "\u001b[31mFileNotFoundError\u001b[39m: File /home/andoni/Downloads/output/cleaned_answer_0.json does not exist"
     ]
    }
   ],
   "source": [
    "answers = pd.read_json(\"/home/andoni/Downloads/output/cleaned_answer_0.json\")\n",
    "instructions = pd.read_json(\"/home/andoni/Downloads/output/cleaned_instruction_0.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abac6bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36120/2168970006.py:24: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.text.tolist()) \\\n",
      "/tmp/ipykernel_36120/2168970006.py:24: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.text.tolist()) \\\n",
      "/tmp/ipykernel_36120/2168970006.py:24: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.text.tolist()) \\\n",
      "/tmp/ipykernel_36120/2168970006.py:24: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.text.tolist()) \\\n",
      "/tmp/ipykernel_36120/2168970006.py:24: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.text.tolist()) \\\n",
      "/tmp/ipykernel_36120/2168970006.py:24: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.text.tolist()) \\\n",
      "/tmp/ipykernel_36120/2168970006.py:24: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.text.tolist()) \\\n",
      "/tmp/ipykernel_36120/2168970006.py:24: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.text.tolist()) \\\n",
      "/tmp/ipykernel_36120/2168970006.py:24: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.text.tolist()) \\\n",
      "/tmp/ipykernel_36120/2168970006.py:24: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.text.tolist()) \\\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    answers = pd.read_json(f\"cleaned/cleaned_answer_{i}.json\")\n",
    "    instructions = pd.read_json(f\"cleaned/cleaned_instruction_{i}.json\")\n",
    "    \n",
    "    # add turn index (assuming aligned by index)\n",
    "    instructions[\"order\"] = range(len(instructions))\n",
    "    answers[\"order\"] = range(len(answers))\n",
    "\n",
    "    # assign types\n",
    "    instructions[\"type\"] = \"instruction\"\n",
    "    answers[\"type\"] = \"answer\"\n",
    "\n",
    "    # map type to numeric priority (instruction first, then answer)\n",
    "    type_order = {\"instruction\": 0, \"answer\": 1}\n",
    "    instructions[\"type_order\"] = instructions[\"type\"].map(type_order)\n",
    "    answers[\"type_order\"] = answers[\"type\"].map(type_order)\n",
    "\n",
    "    # combine and sort properly\n",
    "    combined = pd.concat([instructions, answers])\n",
    "    combined = combined.sort_values(by=[\"conversation_id\", \"order\", \"type_order\"])\n",
    "\n",
    "    # group back into conversation list\n",
    "    conversation_df = combined.groupby(\"conversation_id\") \\\n",
    "        .apply(lambda x: x.text.tolist()) \\\n",
    "        .reset_index(name=\"conversation\")\n",
    "\n",
    "    conversation_df.to_json(f\"conversations/conversation_{i}.json\", orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "74cb135a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/25\u001b[0m [datasets]/25\u001b[0m [datasets]ce-hub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 attrs-25.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 datasets-4.0.0 dill-0.3.8 filelock-3.19.1 frozenlist-1.7.0 fsspec-2025.3.0 hf-xet-1.1.9 huggingface-hub-0.34.4 idna-3.10 multidict-6.6.4 multiprocess-0.70.16 propcache-0.3.2 pyarrow-21.0.0 pyyaml-6.0.2 requests-2.32.5 tqdm-4.67.1 typing-extensions-4.15.0 urllib3-2.5.0 xxhash-3.5.0 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "1ac0edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "conv = pd.read_json(f\"conversations/conversation_0.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "9161fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, conv], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "9e7f1d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Hiru aholku emango zenizkidake osasuntsu egot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Esango al zenidake zeintzuk diren hiru kolore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Deskriba al dezakezu atomo baten egitura nire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[Esango didazue nola murriztu dezakegun kutsad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[Esango zenidake erabaki zaila hartu behar zen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>19995</td>\n",
       "      <td>[Zein da bizitzan borrokatzeko helbururik garr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>19996</td>\n",
       "      <td>[Gustatuko al litzaizuke niretzat AI teknologi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>19997</td>\n",
       "      <td>[Iradoki dezakezu film bat benetan indartsua e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>19998</td>\n",
       "      <td>[Nola prestatzen dituzte ikastetxeek ikasleak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>19999</td>\n",
       "      <td>[Konparatu eta kontrastatu al ditzakezu itsasp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       conversation_id                                       conversation\n",
       "0                    0  [Hiru aholku emango zenizkidake osasuntsu egot...\n",
       "1                    1  [Esango al zenidake zeintzuk diren hiru kolore...\n",
       "2                    2  [Deskriba al dezakezu atomo baten egitura nire...\n",
       "3                    3  [Esango didazue nola murriztu dezakegun kutsad...\n",
       "4                    4  [Esango zenidake erabaki zaila hartu behar zen...\n",
       "...                ...                                                ...\n",
       "19995            19995  [Zein da bizitzan borrokatzeko helbururik garr...\n",
       "19996            19996  [Gustatuko al litzaizuke niretzat AI teknologi...\n",
       "19997            19997  [Iradoki dezakezu film bat benetan indartsua e...\n",
       "19998            19998  [Nola prestatzen dituzte ikastetxeek ikasleak ...\n",
       "19999            19999  [Konparatu eta kontrastatu al ditzakezu itsasp...\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d838049",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(10):\n",
    "    conv = pd.read_json(f\"conversations/conversation_{i}.json\")\n",
    "    df = pd.concat([df, conv], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54f93653",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('conversation_id', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "491b4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('conversations.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20a2f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42d243f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversation'],\n",
       "    num_rows: 200000\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfdacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = \"instruct_en_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afdaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "\"from\": \"human\",\n",
    "\"speech\": \"data/multiturn_instruction/en/wav/instruct_en_0/instruct_en_0-1-user.wav\",\n",
    "\"text\": \"Hey, can you give me, like, three tips for staying healthy?\",\n",
    "\"unit\": null\n",
    "},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "547203f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0805150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('conversations.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26b7454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formated = pd.DataFrame()\n",
    "# Adibidez daukazun dataframe\n",
    "# conversation_id | conversation\n",
    "# 0               | [\"instrukzioa\", \"erantzuna\", \"beste instrukzio bat\", \"beste erantzun bat\"]\n",
    "\n",
    "def format_conversation(conversation, idx):\n",
    "    formatted = []\n",
    "    for i, text in enumerate(conversation):\n",
    "        role = \"human\" if i % 2 == 0 else \"gpt\"\n",
    "        formatted.append({\n",
    "            \"from\": role,\n",
    "            \"speech\": None,\n",
    "            \"text\": text,\n",
    "            \"unit\": None\n",
    "        })\n",
    "    return formatted\n",
    "\n",
    "# DataFramea sortu edo kargatu\n",
    "# df = pd.read_json(\"zure_fitxategia.json\")\n",
    "\n",
    "# ID berria gehitu\n",
    "df_formated[\"id\"] = [f\"instruct_eu_{i}\" for i in range(len(df))]\n",
    "\n",
    "# Conversation berriro formateatu\n",
    "df_formated[\"conversation\"] = [\n",
    "    format_conversation(conv, i) for i, conv in enumerate(df[\"conversation\"])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3fb52476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formated.to_json('conversations.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87633c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(df_formated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78699e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bfcef0647e43609cd09966940e8652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "\n",
    "huggingface_hub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b3d0032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721339f321bd4156988a1f0aecc0440b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b771b512169e4c9cb8398ba69a0f233c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/200 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Ansu/Instruct_S2S_eu/commit/acd8491eabf89872896180359491f31a29c98ce6', commit_message='Upload dataset', commit_description='', oid='acd8491eabf89872896180359491f31a29c98ce6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Ansu/Instruct_S2S_eu', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Ansu/Instruct_S2S_eu'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"Ansu/Instruct_S2S_eu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b0408e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "data = load_dataset(\"Ansu/Instruct_S2S_eu\")\n",
    "data = data['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d48a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'human',\n",
       "  'speech': None,\n",
       "  'text': 'Hiru aholku emango zenizkidake osasuntsu egoteko?',\n",
       "  'unit': None},\n",
       " {'from': 'gpt',\n",
       "  'speech': None,\n",
       "  'text': 'Hona hemen osasuntsu egoteko hiru aholku: dieta orekatua jan, ur asko edanez hidratatuta egon eta gauero gutxienez zazpi ordu lo egin.',\n",
       "  'unit': None}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['conversation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b279880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d87020f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561fefcad7aa46a3a1c44bebbd0d7650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_speech_paths(example):\n",
    "    new_conversation = []\n",
    "    i = 0\n",
    "    for turn in example[\"conversation\"]:\n",
    "        new_turn = turn.copy()\n",
    "        if turn[\"from\"] == \"human\":\n",
    "            new_turn[\"speech\"] = f\"{example['id']}_user_{i}.wav\"\n",
    "        elif turn[\"from\"] == \"gpt\":\n",
    "            new_turn[\"speech\"] = f\"{example['id']}_assistant_{i}.wav\"\n",
    "            i += 1\n",
    "        new_conversation.append(new_turn)\n",
    "    example[\"conversation\"] = new_conversation\n",
    "    return example\n",
    "\n",
    "# if your dataset is a Dataset\n",
    "dataset = data.map(add_speech_paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48f84b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'human',\n",
       "  'speech': 'instruct_eu_9_user_0.wav',\n",
       "  'text': 'Ebaluatu dezakezu esaldi hau ortografia eta gramatika akatsak dio bere bazkaria finnished zuen eta reurant utzi zuen?',\n",
       "  'unit': None},\n",
       " {'from': 'gpt',\n",
       "  'speech': 'instruct_eu_9_assistant_0.wav',\n",
       "  'text': 'Esaldiak bi akats ditu, esaldi zuzena irakurri beharko litzateke: Bazkaria amaitu eta jatetxetik irten zen.',\n",
       "  'unit': None},\n",
       " {'from': 'human',\n",
       "  'speech': 'instruct_eu_9_user_1.wav',\n",
       "  'text': 'Egiaztatu esaldi hau akatsak aurkitzeko: Libariara joan dira oraindik ere.',\n",
       "  'unit': None},\n",
       " {'from': 'gpt',\n",
       "  'speech': 'instruct_eu_9_assistant_1.wav',\n",
       "  'text': 'Esaldiak bi errore ditu. Esaldi zuzenak hauxe irakurri beharko luke: Oraindik ez dira liburutegira joan.',\n",
       "  'unit': None},\n",
       " {'from': 'human',\n",
       "  'speech': 'instruct_eu_9_user_2.wav',\n",
       "  'text': 'Egiaztatu esaldi hau akatsak egiteko: Teknikariak etxeko lanak egin dizkigu gaur gauean.',\n",
       "  'unit': None},\n",
       " {'from': 'gpt',\n",
       "  'speech': 'instruct_eu_9_assistant_2.wav',\n",
       "  'text': 'Esaldiak bi akats ditu, eta esaldi zuzena irakurri beharko litzateke: Irakasleak etxeko lan asko eman dizkigu gaur gauean.',\n",
       "  'unit': None},\n",
       " {'from': 'human',\n",
       "  'speech': 'instruct_eu_9_user_3.wav',\n",
       "  'text': 'Egiaztatu esaldi hau akatsak direla eta: Enpresen irabaziak nabarmen igo dira aurten.',\n",
       "  'unit': None},\n",
       " {'from': 'gpt',\n",
       "  'speech': 'instruct_eu_9_assistant_3.wav',\n",
       "  'text': 'Epaiak bi akats ditu.Esaldi zuzena irakurri beharko litzateke: Enpresaren irabaziak nabarmen igo dira aurten.',\n",
       "  'unit': None},\n",
       " {'from': 'human',\n",
       "  'speech': 'instruct_eu_9_user_4.wav',\n",
       "  'text': 'Egiaztatu esaldi hau akatsak ikusteko: Ikasleek azterketaren emaitzak berreskuratu dituzte oraindik ere.',\n",
       "  'unit': None},\n",
       " {'from': 'gpt',\n",
       "  'speech': 'instruct_eu_9_assistant_4.wav',\n",
       "  'text': 'Esaldiak bi errore ditu.Esaldi zuzenak irakurri beharko luke: Ikasleek oraindik ez dituzte azterketaren emaitzak jaso.',\n",
       "  'unit': None}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[9]['conversation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98734582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hubert_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
